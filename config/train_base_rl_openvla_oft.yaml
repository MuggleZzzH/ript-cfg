defaults:
  - task: libero_spatial
  - algo: openvla_oft_rl
  - reward_function: success
  - paths
  - _self_

# set the path to your data and experiments directories
output_prefix: ${paths.output_prefix}
data_prefix: ${paths.data_prefix}

exp_name: debug # 
variant_name: null
seed: 10000
device: cuda
stage: null # 0 - pretrain autoencoder, 1 - train multitask, 2 - finetune multitask
make_unique_experiment_dir: true # if true, it will create unique experiment directories with name run_00X within that experiment directory, use when debugging
logging_folder: openvla_oft

checkpoint_path: null


train_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 2
  shuffle: true
  num_workers: 6
  persistent_workers: false
  pin_memory: true
  multiprocessing_context: fork
  drop_last: true
  # prefetch_factor: 2

training:
  gradient_accumulation_steps: 1
  n_epochs: 100
  save_interval: 10
  log_interval: 100
  use_amp: false
  use_tqdm: true
  do_profile: false
  save_all_checkpoints: false
  auto_continue: false # if true, it will automatically continue from the end of stage n training for stage n+1 training
  load_obs: true
  cut: 0
  n_steps: 26 # -1 if you want to train for n_epochs, otherwise train for n_steps
  rollout_steps: 2 # -1 if use rollout.interval, otherwise use rollout_steps
  grad_clip: 1.0

  # resume a training run
  resume: false
  resume_path: ""

dataset:
  seq_len: 600
  frame_stack: 1 # this denotes past timestep observations and actions
  obs_seq_len: 1 # this denotes future timestep image observations
  lowdim_obs_seq_len: null # this denotes future timestep lowdim observations
  load_obs_for_pretrain: true # since autoencoder training stage does not require obs
  load_next_obs: true # you know this
  get_pad_mask: true
  load_state: true

rollout:
  enabled: true
  interval: 25
  rollouts_per_env: 48
  num_parallel_envs: 4 # 5 recommended for libero, 1 for metaworld
  max_episode_length: 220

task:
  task_names_to_use: 
    # - put_the_wine_bottle_on_the_rack
    - pick_up_the_black_bowl_next_to_the_plate_and_place_it_on_the_plate
  env_runner:
    num_parallel_envs: 2

logging:
  group: null
  mode: online # set logging.mode=disabled to disable wandb
  project: ${common.wandb_project}
  resume: true
  save_code: true