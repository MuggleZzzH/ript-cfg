defaults:
  - _self_

policy:
  _target_: ript.algos.policies.pi0_oft_policy.PI0_OFT_Policy
  device_id: 0
  norm_stats_path: ${algo.norm_stats_path}
  pretrained_path: /zhaohan/ZJH/openpi_pytorch/checkpoints/pi0_libero_pytorch
  condition_mode: token  # 可选: bias|concat|token
  # PI0 模型训练范围（迁移自代码参数）
  freeze_vision_encoder: true     # 冻结视觉塔
  train_expert_only: true        # 仅训练 Expert 后缀（前缀冻结）

optimizer_factory:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: ${algo.lr}
  betas: [0.9, 0.95]
  weight_decay: ${algo.weight_decay}

scheduler_factory:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  eta_min: 2.5e-6
  last_epoch: -1
  T_max: ${training.n_epochs}

env_runner:
  _target_: ript.env_runner.pi0_libero_runner.Pi0LiberoRunner
  benchmark_name: ${task.benchmark_name}
  rollouts_per_env: ${algo.rollouts_per_env}
  num_parallel_envs: ${algo.num_parallel_envs}
  max_episode_length: ${algo.max_episode_length}
  task_names_to_use: ${task.task_names_to_use}
  use_laplace_sampling: ${algo.use_laplace_sampling}
  scale_factor: ${algo.scale_factor}
  num_steps_wait: 10  # 额外等待步数，可被命令行覆盖

rollout_generator_factory:
  _target_: ript.algos.rl_optimizers.rollout_generator.RolloutGenerator
  _partial_: true
  rloo_batch_size: ${algo.rloo_batch_size}
  demo_batch_size: ${train_dataloader.batch_size}
  use_tqdm: true
  early_stop_percentage: ${algo.early_stop_percentage}
  enable_dynamic_sampling: ${algo.enable_dynamic_sampling}
  use_val_init: ${algo.use_val_init}
  mix_val_init_in_rloo: ${algo.mix_val_init_in_rloo}

rl_optimizer_factory:
  _target_: ript.algos.rl_optimizers.cfg_flow_optimizer_pi0.CFGFlowOptimizerPI0
  _partial_: true
  gradient_accumulation_steps: ${algo.gradient_accumulation_steps}
  alpha_uncond: ${algo.alpha_uncond}
  cf_dropout_p: ${algo.cf_dropout_p}
  stride: ${algo.stride}
  max_windows_per_episode: ${algo.max_windows_per_episode}
  optimizer_batch_size: 4
  grad_norm_clip_model: ${algo.grad_norm_clip_model}
  grad_norm_clip_header: ${algo.grad_norm_clip_header}
  use_binary_advantage: ${algo.use_binary_advantage}

name: pi0_cfg

# algo-level defaults
lr: 2.5e-5
header_lr: 2.5e-5  # 与 lr 相同（默认不区分）
num_parallel_envs: 1
rollouts_per_env: 16
max_episode_length: 300
rloo_batch_size: 8
early_stop_percentage: 1.0
enable_dynamic_sampling: false
use_val_init: false
mix_val_init_in_rloo: false
gradient_accumulation_steps: 1
optimizer_batch_size: 4
eval_only: false
# 采样参数（对齐OpenVLA）
use_laplace_sampling: true
scale_factor: 1.0
# 梯度裁剪（对齐OpenVLA）
grad_norm_clip_model: 1.0
grad_norm_clip_header: 1.0
norm_stats_path: /zhaohan/ZJH/openpi_pytorch/lerobot_dataset/norm_stats.json
rollout_training_task_names: null
frame_stack: 1

# model parameters
model_seed: 7
weight_decay: 0.0001

# rollout stats tracking
rollout_stats_path: null

# CFG Flow optimizer specific parameters
cf_dropout_p: 0.1
alpha_uncond: 0.0
stride: 1
max_windows_per_episode: null
# Advantage模式开关：True=二值化(类似IQL)，False=连续advantage
use_binary_advantage: true

# 推理默认（可被环境变量覆盖：PI0_CFG_SCALE / PI0_IS_POSITIVE）
inference:
  cfg_scale: 3.0
  is_positive_infer: null

dataset:
  seq_len: 50       # PI0专用：匹配窗口chunk长度(H=50)
  frame_stack: 1    # PI0专用：单帧即可
  obs_seq_len: 1    # PI0专用：只需单时刻观测
  lowdim_obs_seq_len: null
  load_obs_for_pretrain: false  # PI0专用：不需要预训练观测
  get_pad_mask: true
  pad_seq_length: false  # PI0专用：不需要序列填充
  load_state: true  # PI0专用：需要初始状态用于rollout
  load_next_obs: false  # PI0专用：不需要future观测

